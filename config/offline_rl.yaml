defaults:
    - agent: maddpg

# Offline RL Settings
target_workspace: ???

# Experiment Settings
env: simple_spread
discrete_action_space: true

experiment: vanilla
seed: 0

num_train_steps: 1e5
replay_buffer_capacity: ${num_train_steps}

eval_frequency: 10
num_eval_episodes: 5

common_reward: true

device: cuda

# Logging Settings
log_frequency: 5000
log_save_tb: true
save_video: true


# hydra configuration
hydra:
    run:
        dir: ./experiment/${now:%Y.%m.%d}/${now:%H%M}_${env}_${agent.name}_orl-${experiment}