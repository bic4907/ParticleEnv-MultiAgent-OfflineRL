defaults:
    - agent: ddpg

# Offline RL Settings
target_workspace: ???

# Experiment Settings
env: simple_spread
discrete_action_space: true

experiment: vanilla
seed: 0

num_train_steps: 40000

eval_frequency: 1000
num_eval_episodes: 5

common_reward: true

device: cuda

# Logging Settings
log_frequency: 5000
log_save_tb: true
save_video: true


# hydra configuration
hydra:
    run:
        dir: ./experiment/${now:%Y.%m.%d}/${now:%H%M}_${env}_${agent.name}_orl-${experiment}